.ipynb
.pdf
CodeTextSplitter
Contents
Python
JS
Markdown
Latex
HTML
CodeTextSplitter
#
CodeTextSplitter allows you to split your code with multiple language support. Import enum
Language
and specify the language.
from
langchain.text_splitter
import
(
RecursiveCharacterTextSplitter
,
Language
,
)
# Full list of support languages
[
e
.
value
for
e
in
Language
]
['cpp',
 'go',
 'java',
 'js',
 'php',
 'proto',
 'python',
 'rst',
 'ruby',
 'rust',
 'scala',
 'swift',
 'markdown',
 'latex',
 'html']
# You can also see the separators used for a given language
RecursiveCharacterTextSplitter
.
get_separators_for_language
(
Language
.
PYTHON
)
['\nclass ', '\ndef ', '\n\tdef ', '\n\n', '\n', ' ', '']
Python
#
Here‚Äôs an example using the PythonTextSplitter
PYTHON_CODE
=
"""
def hello_world():
print("Hello, World!")
# Call the function
hello_world()
"""
python_splitter
=
RecursiveCharacterTextSplitter
.
from_language
(
language
=
Language
.
PYTHON
,
chunk_size
=
50
,
chunk_overlap
=
0
)
python_docs
=
python_splitter
.
create_documents
([
PYTHON_CODE
])
python_docs
[Document(page_content='def hello_world():\n    print("Hello, World!")', metadata={}),
 Document(page_content='# Call the function\nhello_world()', metadata={})]
JS
#
Here‚Äôs an example using the JS text splitter
JS_CODE
=
"""
function helloWorld() {
console.log("Hello, World!");
}
// Call the function
helloWorld();
"""
js_splitter
=
RecursiveCharacterTextSplitter
.
from_language
(
language
=
Language
.
JS
,
chunk_size
=
60
,
chunk_overlap
=
0
)
js_docs
=
js_splitter
.
create_documents
([
JS_CODE
])
js_docs
[Document(page_content='function helloWorld() {\n  console.log("Hello, World!");\n}', metadata={}),
 Document(page_content='// Call the function\nhelloWorld();', metadata={})]
Markdown
#
Here‚Äôs an example using the Markdown text splitter.
markdown_text
=
"""
# ü¶úÔ∏èüîó LangChain
‚ö° Building applications with LLMs through composability ‚ö°
## Quick Install
```bash
# Hopefully this code block isn't split
pip install langchain
```
As an open source project in a rapidly developing field, we are extremely open to contributions.
"""
md_splitter
=
RecursiveCharacterTextSplitter
.
from_language
(
language
=
Language
.
MARKDOWN
,
chunk_size
=
60
,
chunk_overlap
=
0
)
md_docs
=
md_splitter
.
create_documents
([
markdown_text
])
md_docs
[Document(page_content='# ü¶úÔ∏èüîó LangChain', metadata={}),
 Document(page_content='‚ö° Building applications with LLMs through composability ‚ö°', metadata={}),
 Document(page_content='## Quick Install', metadata={}),
 Document(page_content="```bash\n# Hopefully this code block isn't split", metadata={}),
 Document(page_content='pip install langchain', metadata={}),
 Document(page_content='```', metadata={}),
 Document(page_content='As an open source project in a rapidly developing field, we', metadata={}),
 Document(page_content='are extremely open to contributions.', metadata={})]
Latex
#
Here‚Äôs an example on Latex text
latex_text
=
"""
\documentclass
{article}
\b
egin
{document}
\maketitle
\section
{Introduction}
Large language models (LLMs) are a type of machine learning model that can be trained on vast amounts of text data to generate human-like language. In recent years, LLMs have made significant advances in a variety of natural language processing tasks, including language translation, text generation, and sentiment analysis.
\subsection{History of LLMs}
The earliest LLMs were developed in the 1980s and 1990s, but they were limited by the amount of data that could be processed and the computational power available at the time. In the past decade, however, advances in hardware and software have made it possible to train LLMs on massive datasets, leading to significant improvements in performance.
\subsection{Applications of LLMs}
LLMs have many applications in industry, including chatbots, content creation, and virtual assistants. They can also be used in academia for research in linguistics, psychology, and computational linguistics.
\end
{document}
"""
latex_splitter
=
RecursiveCharacterTextSplitter
.
from_language
(
language
=
Language
.
MARKDOWN
,
chunk_size
=
60
,
chunk_overlap
=
0
)
latex_docs
=
latex_splitter
.
create_documents
([
latex_text
])
latex_docs
[Document(page_content='\\documentclass{article}\n\n\x08egin{document}\n\n\\maketitle', metadata={}),
 Document(page_content='\\section{Introduction}', metadata={}),
 Document(page_content='Large language models (LLMs) are a type of machine learning', metadata={}),
 Document(page_content='model that can be trained on vast amounts of text data to', metadata={}),
 Document(page_content='generate human-like language. In recent years, LLMs have', metadata={}),
 Document(page_content='made significant advances in a variety of natural language', metadata={}),
 Document(page_content='processing tasks, including language translation, text', metadata={}),
 Document(page_content='generation, and sentiment analysis.', metadata={}),
 Document(page_content='\\subsection{History of LLMs}', metadata={}),
 Document(page_content='The earliest LLMs were developed in the 1980s and 1990s,', metadata={}),
 Document(page_content='but they were limited by the amount of data that could be', metadata={}),
 Document(page_content='processed and the computational power available at the', metadata={}),
 Document(page_content='time. In the past decade, however, advances in hardware and', metadata={}),
 Document(page_content='software have made it possible to train LLMs on massive', metadata={}),
 Document(page_content='datasets, leading to significant improvements in', metadata={}),
 Document(page_content='performance.', metadata={}),
 Document(page_content='\\subsection{Applications of LLMs}', metadata={}),
 Document(page_content='LLMs have many applications in industry, including', metadata={}),
 Document(page_content='chatbots, content creation, and virtual assistants. They', metadata={}),
 Document(page_content='can also be used in academia for research in linguistics,', metadata={}),
 Document(page_content='psychology, and computational linguistics.', metadata={}),
 Document(page_content='\\end{document}', metadata={})]
HTML
#
Here‚Äôs an example using an HTML text splitter
html_text
=
"""
<!DOCTYPE html>
<html>
<head>
<title>ü¶úÔ∏èüîó LangChain</title>
<style>
body {
font-family: Arial, sans-serif;
}
h1 {
color: darkblue;
}
</style>
</head>
<body>
<div>
<h1>ü¶úÔ∏èüîó LangChain</h1>
<p>‚ö° Building applications with LLMs through composability ‚ö°</p>
</div>
<div>
As an open source project in a rapidly developing field, we are extremely open to contributions.
</div>
</body>
</html>
"""
html_splitter
=
RecursiveCharacterTextSplitter
.
from_language
(
language
=
Language
.
MARKDOWN
,
chunk_size
=
60
,
chunk_overlap
=
0
)
html_docs
=
html_splitter
.
create_documents
([
html_text
])
html_docs
[Document(page_content='<!DOCTYPE html>\n<html>\n    <head>', metadata={}),
 Document(page_content='<title>ü¶úÔ∏èüîó LangChain</title>\n        <style>', metadata={}),
 Document(page_content='body {', metadata={}),
 Document(page_content='font-family: Arial, sans-serif;', metadata={}),
 Document(page_content='}\n            h1 {', metadata={}),
 Document(page_content='color: darkblue;\n            }', metadata={}),
 Document(page_content='</style>\n    </head>\n    <body>\n        <div>', metadata={}),
 Document(page_content='<h1>ü¶úÔ∏èüîó LangChain</h1>', metadata={}),
 Document(page_content='<p>‚ö° Building applications with LLMs through', metadata={}),
 Document(page_content='composability ‚ö°</p>', metadata={}),
 Document(page_content='</div>\n        <div>', metadata={}),
 Document(page_content='As an open source project in a rapidly', metadata={}),
 Document(page_content='developing field, we are extremely open to contributions.', metadata={}),
 Document(page_content='</div>\n    </body>\n</html>', metadata={})]
previous
Character
next
NLTK
Contents
Python
JS
Markdown
Latex
HTML
By Harrison Chase
¬© Copyright 2023, Harrison Chase.
Last updated on Jun 09, 2023.